{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab50763-91a9-4e60-aba3-f79b3f6cf64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import numpy.random      as ra\n",
    "import numpy.matlib      as mlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack     as spfft # For the Fourier transform\n",
    "#import scipy.optimize    as scopt # For minimising objective functions with constraints\n",
    "#import cvxpy             as cvx   # Library for convex optimization\n",
    "import pywt                       # Wavelet transform software \n",
    "\n",
    "from matplotlib.image     import imread\n",
    "from skimage.util         import random_noise\n",
    "from scipy                import signal\n",
    "from IPython.display      import display, Math, Latex\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efbdd8-512b-4273-9294-f455c4f3c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573c744-6365-4f08-9883-8b0abaa7032e",
   "metadata": {},
   "source": [
    "## ***Before you start***\n",
    "\n",
    "#### Please make sure you have installed the libraries listed in the header and have got the data and the helper.py script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca36880-abfd-425d-90b6-46bcb53b9a4c",
   "metadata": {},
   "source": [
    "# Sparsity, denoising and compressed sensing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf70d2-a186-439d-a182-837fae9be874",
   "metadata": {},
   "source": [
    "During the lectures, we discussed the role of the $\\ell_1$ and $\\ell_2$ norm in computing solutions to an underdetermined system of equations. We also described how sparsity and incoherent random sampling play a crucial role in compressive sensing reconstruction. In this practical, we will explore these concepts in more detail. \n",
    "\n",
    "This practical consists of two parts. Part A deals with signal denoising and sparsity, and part B with compressed sensing reconstruction of an MRI image.\n",
    "\n",
    "I hope you enjoy it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c41ff-3aa3-4fcb-b49c-3adbc2c3b426",
   "metadata": {},
   "source": [
    "## A. Sparse signal denoising:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf3237c-43f8-49da-982d-91aed5840c42",
   "metadata": {},
   "source": [
    "In this section, we are going to explore denoising of a $1$D sparse signal containing random noise. We will attempt this by using:\n",
    "\n",
    "\n",
    "- $\\ell_2$  regularization: \n",
    " \n",
    "   $\\hat{x} = \\underset{x}{\\operatorname{argmin}} \\frac{1}{2}\\| \\hat{x}-y \\| _2^2 + \\lambda\\frac{1}{2}\\|\\hat{x}\\|_2$\n",
    "\n",
    "   where $\\|x\\|_2 = \\sqrt{\\sum x_i^2}$\n",
    "   \n",
    "\n",
    "-   $\\ell_1$ regularization:\n",
    "   \n",
    "     $\\hat{x} = \\underset{x}{\\operatorname{argmin}} \\frac{1}{2}\\| \\hat{x}-y \\| _2^2 + \\lambda\\frac{1}{2}\\|\\hat{x}\\|_1$\n",
    "\n",
    "    where $\\|x\\| = \\sum |x_i|$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b680a2f-8184-4a2f-9d66-db71f5373e04",
   "metadata": {},
   "source": [
    "**a)** First, let's start by generating a sparse-noisy signal $y$ and plotting the denoised reconstruction $\\hat{x}$:\n",
    "1. Generate a \"signal\" $y = x + n$, of length $100$ and with $7$ non-zero coefficients. Here, n is random Gaussian noise with std, $\\sigma = 0.05$\n",
    "   \n",
    "2. The closed form solution for the $\\ell_2$ minimization problem is given by:\n",
    "$$\\hat x = \\frac{1}{1+\\lambda} y $$\n",
    "\n",
    "plot this solution for $\\lambda = [0.01,0.05,0.1,0.5]$\n",
    "\n",
    "Question: Is $\\hat{x}$ sparse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050a372-d6f5-42a7-9e57-f8c1aab7e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a length-100 vector, x, with 7 randomly distributed non-zero coeﬃcients\n",
    "L   =                                   # Lenght vector\n",
    "nzc = [0,1]    # Choose 7 non-zero coefficients between [0,1]\n",
    "x   = np.array( nzc +[0] *(L- len(nzc) ))  # create an array with zeros everywhere but at the 7 selected locations\n",
    "x   =      # Shuffle the vector components\n",
    "\n",
    "# Generate your \"measurements\" y by adding random Gaussian noise with standard deviation $\\sigma$\n",
    "sigma = \n",
    "y     = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687c2f4-228a-4cf6-99b3-e1233f4b7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (15,3))\n",
    "plt.stem( )\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f16105-7e23-4608-84b3-b6db8f9b6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the $\\ell_2$ solution (xhat) for differet lambdas\n",
    "Lambda = \n",
    "for lamb in Lambda:\n",
    "    xhat = \n",
    "    plt.figure( figsize = (15,3))\n",
    "    plt.stem(  )\n",
    "    plt.title( 'lambda = %.2f' %lamb)\n",
    "    plt.xlabel('n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5cb40-5504-40ad-be03-06ea197490bb",
   "metadata": {},
   "source": [
    "**b)** Instead of the $\\ell_2$ regularization, we are going to use the $\\ell_1$. It turns out that since the variables $\\hat{x}_i$ are independent, we can minimise the problem for each of them independently, that is $\\arg \\min \\frac{1}{2}\\| \\hat{x}_i-y_i \\| _2^2 + \\lambda\\frac{1}{2}\\|\\hat{x}_i\\|_1$. The solution, has a closed form, given by:\n",
    "\n",
    "- If $y_i<-\\lambda \\rightarrow  \\hat{x}_i = y_i +\\lambda$  \n",
    "  \n",
    "- If $|y_i|< \\lambda\\rightarrow \\hat{x}_i = 0$   \n",
    "  \n",
    "- If $y_i>\\lambda \\rightarrow \\hat{x}_i = y_i -\\lambda$  \n",
    "\n",
    "These conditions define the so-called `soft-thresholding` function.\n",
    "\n",
    "Write the \\emph{soft-thresholding} function that takes as arguments $y$ and $\\lambda$ and returns $\\hat{x}$ in the interval $[-15,15]$ with $\\lambda = 2$\n",
    "\n",
    "What happens when $y< \\lambda$ and when $y> \\lambda$?\n",
    "\n",
    "Apply your `soft-thresholding` function to the noisy signal $y$ for $λ = [0.01,0.05,0.1,0.2]$.\n",
    "\n",
    "Is the solution sparse?\n",
    "\n",
    "What does happen if you keep increasing $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c68f43-3af5-460e-8307-34378a3e3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def STH(y, L): \n",
    "    #SoftThresh -- Apply Soft Threshold to y\n",
    "    res = (abs() - )\n",
    "    res = (res +abs(res)) /2.\n",
    "    xh  = np.sign(y) *res\n",
    "    return xh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974dcb1e-9214-4d79-aaa4-1ca03dda8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the output for t in [-15, 15] and lambda = 2\n",
    "b    = \n",
    "yt   = np.r_[-b:b:0.01]\n",
    "lbd  = \n",
    "\n",
    "plt.figure( figsize = (6,3))\n",
    "plt.plot(yt, STH(yt, lbd))\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(r\"$\\hat{x}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0c2ad-ab37-49f9-b6bf-3c6200bd8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda = [0.01,0.05,0.1,0.2]\n",
    "for lamb in Lambda:\n",
    "    xhat = \n",
    "    plt.figure( figsize = (8,2))\n",
    "    plt.stem( abs(xhat) )\n",
    "    plt.title( 'lambda = %.2f' %lamb)\n",
    "    plt.xlabel('n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913faa6e-919c-4080-af06-ca4f2e49a868",
   "metadata": {},
   "source": [
    "## B. 2D-compressed sensing reconstruction of MRI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd70130-e036-49fd-bb9d-f8e27472ae8f",
   "metadata": {},
   "source": [
    "In this seciton we are going to work with [brain data](https://inst.eecs.berkeley.edu/~ee123/sp16/hw/brain.npz) data provided [Prof. Michael Lustig](https://people.eecs.berkeley.edu/~mlustig/). \n",
    "\n",
    "Note: In the helper.py file provided, you can find the functions we need to visualise wavelet transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0753c-3f74-42dd-877d-ddc08bf83c85",
   "metadata": {},
   "source": [
    "#### a) Non-uniform random sampling\n",
    "\n",
    "The energy in many natural images is concentrated in lower spatial frequencies; thus, more samples should be allocated there. \n",
    "The provided brain data contain two $3$-fold undersampling masks, measuring similar number of samples, and their corresponding probability density functions (PDF):\n",
    "\n",
    "-  Uniform mask: `mask_unif`  and `pdf_unif`\n",
    "-  Variable desnity mask: `mask_vardens` and `pdf_vardens`\n",
    "\n",
    "For each mask:\n",
    "\n",
    "1. Compute the 2D Fourier transform of the image using a centred 2D FFT. \n",
    "\n",
    "2. Multiply by the uniform mask, divide by the appropriate PDF (called density compensation), and compute the zero-filled Fourier transform    \n",
    "3. Display the image and the difference image compared to the original image.\n",
    "\n",
    "Which gives you a better reconstruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2952cfc-21fd-43ca-a586-26023c442766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load brain data\n",
    "data = np.load(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6953df-ac1e-4df8-9f45-f5f5327005ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the brain data and store it in the corresponding variables\n",
    "im, mask_unif, mask_vardens, pdf_unif, pdf_vardens = \\\n",
    "data['im'], data['mask_unif'], data['mask_vardens'], data['pdf_unif'], data['pdf_vardens'], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e99caf-e948-4068-a00c-44b2520018fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "M  = fft2c ()\n",
    "Mu  =  * mask_unif / pdf_unif\n",
    "imu = ifft2c ( )\n",
    "\n",
    "Mv  =  * mask_vardens / pdf_vardens\n",
    "imv = ifft2c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c20012a-4bf0-4bb1-bc7c-9e4f09add3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot (1,3,1)\n",
    "imshowgray (abs (im) )\n",
    "plt.title(\"Ground truth\")\n",
    "#\n",
    "plt.subplot (1,3,2)\n",
    "imshowgray (abs (imu) )\n",
    "plt.title(\"Uniform density random sampling\")\n",
    "#\n",
    "plt.subplot (1,3,3)\n",
    "imshowgray (abs (im-imu) )\n",
    "plt.title(\"Reconstruction error\")\n",
    "plt. show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689c164-812f-40f5-a97d-0d6a1074164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot (1,3,1)\n",
    "imshowgray (abs (im) )\n",
    "plt.title(\"Ground truth\")\n",
    "#\n",
    "plt.subplot (1,3,2)\n",
    "imshowgray (abs (imv) )\n",
    "plt.title(\"Variable density random sampling\")\n",
    "#\n",
    "plt.subplot (1,3,3)\n",
    "imshowgray (abs (im-imv) )\n",
    "plt.title(\"Reconstruction error\")\n",
    "plt. show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b29b7d-7e6b-4a3b-9c65-5721eab12dd7",
   "metadata": {},
   "source": [
    "Both sampling masks distribute the aliasing energy throughout the image, but the \"noise\" from the variable density mask appears much more like white noise. This indicates that the incoherence is higher for the varaible density sampling pattern than it is for the unform density sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46cc59-2540-4eb5-a457-eb635d243f5c",
   "metadata": {},
   "source": [
    "### b) Reconstruction sampling the k-space randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54807775-fb52-4405-9fec-739b6427d482",
   "metadata": {},
   "source": [
    "In this exercise, we are going to reconstruct the image we have obtained by sampling the k-sapace using the variable density mask. To that end:\n",
    "\n",
    "    1. Implement a Projection Over Convex Sets (POCS) type algorithm by filling the skeleton provided--this is an simple POCS type example. \n",
    "    \n",
    "    2. Get an idea of reasonable values for lambda by examining what would be thresholded in the wavelet decomposition.\n",
    "    \n",
    "    3. Reconstruct your image and plot the reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1681d84-959e-42e1-8b34-4ffb1757fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 2d POCS type altorithim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d8168-d9ef-4ffd-9920-90172c7e2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POCS2D(Y, lam, nitr, ref=None):\n",
    "    \"\"\"Projection Over Convex Sets (POCS)\"\"\"\n",
    "    err = np.zeros ( (nitr,))\n",
    "    Xi  = Y.copy()\n",
    "    for i in range(nitr):\n",
    "    # Enforce sparsity by decomposing in Fourier and Wavelets\n",
    "        xi  = ifft2c( )    #  Compute the 2D inverse Fourier transform to get an estimate of the signal      \n",
    "        xdw = dwt2( )      #  Compute the 2D WT transform of the estimated signal   \n",
    "        ctxdw = ComplexSoftThresh( , lam) # Threshold (complex domain)\n",
    "        xi    =  idwt2 (  )            # compute the invers of the 2D WT      \n",
    "        xi = fft2c(xi)\n",
    "        # Enforce data consistency by filling in missed k-space points \n",
    "        Xi = xi*(Y==0) + Y\n",
    "        err[i] = np.linalg.norm(Xi - ref)\n",
    "        if ref is not None:\n",
    "         print( 'It %d: %0.2f' % (i, err[i]))\n",
    "    return ifft2c(Xi), err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098d75c-5e53-4184-b58f-7b00dd12bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  You want a significant number of coefficients to be below λ, but not all of them\n",
    "#  Check the effect of lambda on the different wavelet scales start by lower values of lambda~ 0.01 and increase them\n",
    "\n",
    "lamb = 0.2 # Choose a lambda\n",
    "\n",
    "Wimv = dwt2( ) # get the wavelet decomposition for the \"variable density\" reconstructed image.\n",
    "imshowgray(abs( ) > lamb) # Check what you have left out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee42e2-2283-4675-9fda-071719e76da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mv    =   * mask_vardens # Mask data with variable density mask (not normalised)\n",
    "\n",
    "# Call reconstruction algorithm\n",
    "nitr       =   # Run for at least 15 iterations\n",
    "lam        =  # selected lambda\n",
    "recon, err = POCS2D(Mv, lam, nitr, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c98af0-5baf-4ae4-8777-fe6728187769",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (10,4))\n",
    "plt.subplot (1,2,1)\n",
    "plt. plot (range (nitr), err)\n",
    "plt.title(\"Reconstruciton error\")\n",
    "#\n",
    "plt.subplot (1,2,2)\n",
    "imshowgray (abs (recon) )\n",
    "plt.title(\"Reconstructed image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed996b-af86-45fa-ae85-006d8b1dc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04625e-e8b3-4c64-89a9-a2b7c3a99bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3156b-7081-4bec-a837-fc013856dba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
